{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Welcome to the world of machine learning (ML)! To actually implement some of the machine learning architectures we've discussed, we're going to be using several python packages. These packages have been developed to make the difficult business of implementing and training ML networks simpler and easier. Let's talk quickly about some of the software packages that we'll be using.\n",
    "\n",
    "## Numpy\n",
    "Numpy is a general-purpose framework for doing all kinds of numeric calculations in python. Under the hood, it calls compiled C functions, so it's incredibly fast. Any time you're trying to do some computational heavy-lifting, you should be using numpy instead of pure python.\n",
    "\n",
    "## TensorFlow\n",
    "TensorFlow is a package developed by Google for defining and working with ML applications. It is both a machine learning _frontend_ (i.e., the series of functions that the user calls to define and train the machine learning application) and computational _backend_ (i.e., the machinery that's actually training and testing the machine learning networks). Although it is possible to write ML apps entirely in TensorFlow, there are other packages available to serve as the frontend, while using TensorFlow as a backend. TensorFlow has the nice feature of automatically leveraging GPU resources if they are available, which can dramatically speed up the ML learning and prediction processes.\n",
    "\n",
    "## Keras\n",
    "Keras is a python module that serves as a frontend for ML applications. It is much more user-friendly than TensorFlow's frontend, and so it's a popular choice for quickly getting applications off the ground. Keras is able to plug into several different ML backends, including TensorFlow, so using Keras as a frontend and TensorFlow as a backend is a very common approach to ML apps.\n",
    "\n",
    "\n",
    "# Installation\n",
    "Okay, now that we've discussed some of the basics, let's talk about how to actually get started. The easiest way to keep track of the various python packages we need to install is to use [Anaconda](https://www.anaconda.com/distribution/). If you haven't already installed anaconda on your machine, you should start there.\n",
    "\n",
    "Next, let's create a new envrionment for doing all of our machine learning tasks. This helps make sure that we don't have conflicting versions of underlying libraries (like numpy) causing inconsistencies. From the command line prompt, let's do:\n",
    "\n",
    "```bash\n",
    "conda create -n ml python=3.7 anaconda\n",
    "```\n",
    "This will create a new environment called `ml` and install a default list of packages.\n",
    "\n",
    "Next, let's make sure we have all the necessary pre-requisites for installing TensorFlow and Keras. We can get most of what we need from anaconda:\n",
    "\n",
    "```bash\n",
    "conda activate ml\n",
    "conda install numpy scipy scikit-learn\n",
    "```\n",
    "Once that's done, we'll actually install TensorFlow and Keras using conda:\n",
    "```bash\n",
    "conda install tensorflow keras\n",
    "```\n",
    "\n",
    "Now, to test that we have a working installation, let's open a new python interpreter to see if we've got everything working:\n",
    "```python\n",
    ">>> import tensorflow\n",
    ">>> import keras\n",
    "Using TensorFlow backend\n",
    "\n",
    "```\n",
    "Voil√†! We have a working installation and can now get down to the business of doing machine learning!\n",
    "\n",
    "# Testing your Installation\n",
    "You can execute the code block below to see if you're ready to run Keras and TensorFlow. Note that you should be using a jupyter kernel in the environment where the packages are installed (called `ml` in the above example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HERA-specific Software\n",
    "The raw data that HERA generates are what is referred to as \"visibility data\". These datasets are very complicated, and are interpreted with dedicated libraries for interpreting and handling them. One such library widely used in the HERA collaboration is [pyuvdata](https://github.com/RadioAstronomySoftwareGroup/pyuvdata/), which allows for reading, writing, and manipulating visibility datasets in python.\n",
    "\n",
    "## Installing `h5py`\n",
    "We'll be interacting mostly with UVH5 files, a specific way of encapsulating visibility data in an HDF5 data format. So, we'll need to make sure the python-specific bindings for HDF5 (`h5py`) are installed:\n",
    "```bash\n",
    "conda install h5py\n",
    "```\n",
    "\n",
    "## Installing `pyuvdata`\n",
    "There are several ways to install pyuvdata--we'll go through them below, starting with the easiest ways.\n",
    "\n",
    "### Using anaconda\n",
    "`pyuvdata` is distributed as a conda package, and so we can install it using our familiar conda tools. We need to specify the `conda-forge` installation channel, but otherwise it's no more difficult than any of the other packages we installed above:\n",
    "\n",
    "```bash\n",
    "conda install -c conda-forge pyuvdata\n",
    "```\n",
    "\n",
    "This will install pyuvdata as well as any dependencies that may be missing. As mentioned above, we want to make sure that `h5py` is installed, which we'll need for reading and writing UVH5 datasets (a particular storage format for visibility data).\n",
    "\n",
    "### Using pip\n",
    "`pyuvdata` is also available as a pip package. Personally I find anaconda to be a more robust package manager than pip, but it's available as an option as well.\n",
    "\n",
    "```bash\n",
    "pip install pyuvdata\n",
    "```\n",
    "\n",
    "### Install from Source\n",
    "We can install `pyuvdata` from source as well, which allows for us to have the latest \"bleeding edge\" installed. First we use git to get a local copy of the repo, and then install the package.\n",
    "\n",
    "```bash\n",
    "git clone https://github.com/RadioAstronomySoftwareGroup/pyuvdata/\n",
    "cd pyuvdata\n",
    "python setup.py install\n",
    "```\n",
    "\n",
    "## Testing your Installation\n",
    "Execute the block below to make sure that we can read UVH5 files. The generic object that contains visibility data in `pyuvdata` is the `UVData` object. When interfacing with files, we'll be primarily using these objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyuvdata import UVData\n",
    "uvd = UVData()\n",
    "uvd.read_uvh5(\"data/zen.2458432.34569.uvh5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml]",
   "language": "python",
   "name": "conda-env-ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
